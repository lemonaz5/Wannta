{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing IR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup commonly used function and constraint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as output:\n",
    "        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_object(filename):\n",
    "    r = {}\n",
    "    with open(filename, 'rb') as f:\n",
    "        r = pickle.load(f)\n",
    "    return r\n",
    "\n",
    "sentenceVectorFile = 'senVec.txt'\n",
    "sentenceDictFile = 'sen2vec.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define prepare_model function\n",
    "By checking if file at 'sentenceDictFile' variable exist or not. If not it will create such file, otherwise it will load from file. The output of this function is sentenceDatabase which is a numpy array with dimension of length of all sentence in database by 300, each row is a sentence vector from precompiled fastText. Next is sen2vec is like sentenceDatabase but instead of index of number, the index is the sentence itself. And lastly idx2sen which connected the gap between the two previous mentioned variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model():\n",
    "    if os.path.isfile(sentenceDictFile):\n",
    "        sen2vec = load_object(sentenceDictFile)\n",
    "        idx2sen = {}\n",
    "        for idx, sen in enumerate(sen2vec):\n",
    "            idx2sen[idx] = sen\n",
    "        \n",
    "        sentenceDatabase = np.zeros((len(sen2vec), 300))\n",
    "        for i in range(len(sen2vec)):\n",
    "            for j in range(300):\n",
    "                sentenceDatabase[i][j] = sen2vec[idx2sen[i]][j]\n",
    "        return sentenceDatabase, idx2sen, sen2vec\n",
    "    else:\n",
    "        sen2vec = {}\n",
    "        with open(sentenceVectorFile, 'r') as file:\n",
    "            for idx, line in enumerate(file):\n",
    "                sentence = line.strip().split(' ')\n",
    "                vector = sentence[-300:]\n",
    "                sentence = \"\".join(sentence[:len(sentence) - 300])\n",
    "                sen2vec[sentence] = list(map(lambda x: float(x), vector))\n",
    "        save_object(sen2vec, sentenceDictFile)\n",
    "        idx2sen = {}\n",
    "        for idx, sen in enumerate(sen2vec):\n",
    "            idx2sen[idx] = sen\n",
    "        \n",
    "        sentenceDatabase = np.zeros((len(sen2vec), 300))\n",
    "        for i in range(len(sen2vec)):\n",
    "            for j in range(300):\n",
    "                sentenceDatabase[i][j] = sen2vec[idx2sen[i]][j]\n",
    "        return sentenceDatabase, idx2sen, sen2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define talkVec function\n",
    "This function compare inputSentenceVector (expected to be np array with dimension of (300, )) with rest of sentenceDatabase using consine similarity, and output the cloest sentence in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talkVec(sentenceDatabase, idx2sen, sen2vec, inputSentenceVector):\n",
    "    inputAb = np.linalg.norm(inputSentenceVector,ord=1)\n",
    "    output = sentenceDatabase.dot(inputSentenceVector)\n",
    "    for i in range(sentenceDatabase.shape[0]):\n",
    "        output[i] /= (np.linalg.norm(sentenceDatabase[i], ord=1))*inputAb\n",
    "    sumAll = np.sum(output)\n",
    "    output = output/sumAll\n",
    "    outIdx = np.argmax(output)\n",
    "    return idx2sen[outIdx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define main function\n",
    "As of right now. this is for testing only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "เอาที่แกตอบได้ก็ได้\n",
      "เอาที่แกตอบได้ก็ได้\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    sentenceDatabase, idx2sen, sen2vec = prepare_model()\n",
    "    testIdx = 1\n",
    "    print(idx2sen[testIdx])\n",
    "    print(talkVec(sentenceDatabase, idx2sen, sen2vec, np.array(sen2vec[idx2sen[testIdx]])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing another IR Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentenceHumanVectorFile = 'senHumanVec.txt'\n",
    "sentenceHumanDictFile = 'senHuman2vec.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model_human():\n",
    "    if os.path.isfile(sentenceHumanDictFile):\n",
    "        senHuman2vec = load_object(sentenceHumanDictFile)\n",
    "        idx2senHuman = {}\n",
    "        for idx, sen in enumerate(senHuman2vec):\n",
    "            idx2senHuman[idx] = sen\n",
    "        \n",
    "        sentenceHumanDatabase = np.zeros((len(senHuman2vec), 300))\n",
    "        for i in range(len(senHuman2vec)):\n",
    "            for j in range(300):\n",
    "                sentenceHumanDatabase[i][j] = senHuman2vec[idx2senHuman[i]][j]\n",
    "        return sentenceHumanDatabase, idx2senHuman, senHuman2vec\n",
    "    else:\n",
    "        senHuman2vec = {}\n",
    "        with open(sentenceHumanVectorFile, 'r') as file:\n",
    "            for idx, line in enumerate(file):\n",
    "                sentence = line.strip().split(' ')\n",
    "                vector = sentence[-300:]\n",
    "                sentence = \"\".join(sentence[:len(sentence) - 300])\n",
    "                senHuman2vec[sentence] = list(map(lambda x: float(x), vector))\n",
    "        save_object(senHuman2vec, sentenceHumanDictFile)\n",
    "        \n",
    "        idx2senHuman = {}\n",
    "        for idx, sen in enumerate(senHuman2vec):\n",
    "            idx2senHuman[idx] = sen\n",
    "        \n",
    "        sentenceHumanDatabase = np.zeros((len(senHuman2vec), 300))\n",
    "        for i in range(len(senHuman2vec)):\n",
    "            for j in range(300):\n",
    "                sentenceHumanDatabase[i][j] = senHuman2vec[idx2senHuman[i]][j]\n",
    "        return sentenceHumanDatabase, idx2senHuman, senHuman2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def talkHmanVec(sentenceHumanDatabase, idx2senHuman, senHuman2vec, idx2sen, inputSentenceVector):\n",
    "    inputAb = np.linalg.norm(inputSentenceVector,ord=1)\n",
    "    output = sentenceHumanDatabase.dot(inputSentenceVector)\n",
    "    for i in range(sentenceHumanDatabase.shape[0]):\n",
    "        output[i] /= (np.linalg.norm(sentenceHumanDatabase[i], ord=1))*inputAb\n",
    "    sumAll = np.sum(output)\n",
    "    output = output/sumAll\n",
    "    outIdx = np.argmax(output)\n",
    "    return idx2sen[outIdx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ละทำmodalแก้หรือเป็นอีกหน้าดีอ่ะ\n",
      "อ้ออาจจะมีไอค่อนด้วยงั้นอีกหน้าก็ดี\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    sentenceDatabase, idx2sen, sen2vec = prepare_model()\n",
    "    sentenceHumanDatabase, idx2senHuman, senHuman2vec = prepare_model_human()\n",
    "    testIdx = 300\n",
    "    print(idx2sen[testIdx])\n",
    "    print(talkHmanVec(sentenceDatabase, idx2sen, sen2vec, idx2sen, np.array(sen2vec[idx2sen[testIdx]])))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
