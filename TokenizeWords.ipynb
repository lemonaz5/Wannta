{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pythainlp.tokenize import word_tokenize\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove link and replace with keyword\n",
    "Remove any string seperate by whitespace that begin with http:// or https:// and replace it with \"<LINK>\" keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with_link = []\n",
    "\n",
    "def replace_link(idx, text, replace_text = '<LINK>'):\n",
    "    new_text = text\n",
    "    pattern = re.compile(\"http[s]{0,1}://\")\n",
    "    if pattern.search(new_text):\n",
    "        with_link.append(idx)\n",
    "        new_text = []\n",
    "        for w in text.split(\" \"):\n",
    "            if pattern.search(w):\n",
    "                new_text += [replace_text]\n",
    "            else:\n",
    "                new_text += [w]\n",
    "        new_text = \" \".join(new_text)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define constant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputFile = 'sentences-30k.txt'\n",
    "outputFile = 'tokenized_out-30k-space.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open input file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "idx = 0\n",
    "\n",
    "with open(inputFile, 'r') as file:\n",
    "    for line in file:\n",
    "        if len(line.strip()) > 0:\n",
    "            data.append(replace_link(idx, re.sub(r'[5]{2,}', '555', line.strip())))\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35434/35434 [00:22<00:00, 1586.42it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "words = set()\n",
    "tokenized = []\n",
    "for line in tqdm(data):\n",
    "    tokenized.append(word_tokenize(line))\n",
    "    words = set(tokenized[-1]) | words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_words = set()\n",
    "new_tokenized = []\n",
    "for idx, line in enumerate(tokenized):\n",
    "    newTokenize = []\n",
    "    if idx in with_link:\n",
    "        for w in line:\n",
    "            if '<LINK>' in w.split(' '):\n",
    "                newTokenize += ['<LINK>']\n",
    "                if len(w.split(' ')) > 1:\n",
    "                    newTokenize += [' ']\n",
    "                    ttmp = w.split(' ')[1:]\n",
    "                    newTokenize += word_tokenize(\" \".join(ttmp), engine='newmm')\n",
    "            else:\n",
    "                newTokenize += word_tokenize(w, engine='newmm')\n",
    "    else:\n",
    "        for w in line:\n",
    "            newTokenize += word_tokenize(w, engine='newmm')\n",
    "    \n",
    "    new_tokenized.append(newTokenize)\n",
    "    new_words = new_words | set(newTokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Writing output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(outputFile, 'w') as file:\n",
    "    for line in new_tokenized:\n",
    "        file.write(\"{}\\n\".format(\" \".join(line)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
